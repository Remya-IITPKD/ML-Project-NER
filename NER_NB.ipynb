{"cells":[{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3222,"status":"ok","timestamp":1729577913506,"user":{"displayName":"Remya Gunasekharan","userId":"01582042654376419065"},"user_tz":-330},"id":"5fHuSHg4b_L0","outputId":"e040eae9-a989-4eaf-eb53-ae5dc98c1b80"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n","Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.15.2)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"]}],"source":["!pip install datasets"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45883,"status":"ok","timestamp":1729577964250,"user":{"displayName":"Remya Gunasekharan","userId":"01582042654376419065"},"user_tz":-330},"id":"QJQzTmLcb1mN","outputId":"17a4bdb2-ef1c-4ee4-9ff3-f1bfaea13952"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","       B-LOC       0.55      0.86      0.67       809\n","      B-MISC       0.75      0.68      0.71       341\n","       B-ORG       0.48      0.66      0.56       848\n","       B-PER       0.60      0.78      0.68       810\n","       I-LOC       0.89      0.32      0.47       126\n","      I-MISC       0.61      0.52      0.56       102\n","       I-ORG       0.62      0.39      0.48       414\n","       I-PER       0.84      0.60      0.70       581\n","           O       0.99      0.96      0.98     19021\n","\n","    accuracy                           0.91     23052\n","   macro avg       0.71      0.64      0.65     23052\n","weighted avg       0.93      0.91      0.92     23052\n","\n"]}],"source":["import nltk\n","from sklearn.svm import SVC\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction import DictVectorizer\n","from datasets import load_dataset\n","\n","# Download necessary NLTK data\n","nltk.download('averaged_perceptron_tagger')\n","\n","# Load the CoNLL 2003 dataset\n","dataset = load_dataset('conll2003')\n","\n","# Sample dataset structure\n","# Each entry in dataset['train'] or dataset['test'] looks like:\n","# {\n","#   'id': '0',\n","#   'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'],\n","#   'ner_tags': [3, 0, 3, 0, 0, 0, 3, 0, 0],  # NER tag integers\n","#   'pos_tags': [22, 23, 20, 23, 21, 23, 20, 23, 23],  # POS tag integers\n","#   'chunk_tags': [11, 10, 11, 10, 10, 10, 11, 10, 10]\n","# }\n","\n","# Load the train/test sets\n","#train_data = dataset['train']\n","train_data = dataset['train'].shuffle(seed=42).select(range(int(len(dataset['train']) * 0.50)))\n","test_data = dataset['test'].shuffle(seed=42).select(range(int(len(dataset['test']) * 0.50)))\n","\n","# Get NER tag mappings from integers to label strings\n","label_names = dataset['train'].features['ner_tags'].feature.names\n","\n","# Convert NER tags into readable labels\n","def convert_tags_to_labels(tag_list):\n","    return [label_names[tag] for tag in tag_list]\n","\n","# Feature extraction function for each word\n","def extract_features(sentence, index):\n","    word = sentence[index]\n","    features = {\n","        'word': word,\n","        'is_first': index == 0,\n","        'is_last': index == len(sentence) - 1,\n","        'is_capitalized': word[0].isupper(),\n","        'is_all_caps': word.isupper(),\n","        'is_all_lower': word.islower(),\n","        'prefix-1': word[0],\n","        'prefix-2': word[:2],\n","        'prefix-3': word[:3],\n","        'suffix-1': word[-1],\n","        'suffix-2': word[-2:],\n","        'suffix-3': word[-3:],\n","        'prev_word': '' if index == 0 else sentence[index - 1],\n","        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n","        'is_numeric': word.isdigit(),\n","        'capitals_inside': word[1:].lower() != word[1:]\n","    }\n","    return features\n","\n","# Prepare dataset for feature extraction\n","def transform_to_dataset(dataset):\n","    X, y = [], []\n","    for i in range(len(dataset)):\n","        tokens = dataset[i]['tokens']\n","        tags = convert_tags_to_labels(dataset[i]['ner_tags'])\n","        for index in range(len(tokens)):\n","            X.append(extract_features(tokens, index))\n","            y.append(tags[index])\n","    return X, y\n","\n","# Transform the train and test datasets\n","X_train, y_train = transform_to_dataset(train_data)\n","X_test, y_test = transform_to_dataset(test_data)\n","\n","# Convert features to numerical vectors\n","vec = DictVectorizer(sparse=False)\n","X_train = vec.fit_transform(X_train)\n","X_test = vec.transform(X_test)\n","\n","# Initialize and train the Naive BAyes\n","\n"," #Initialize and train the Multinomial Naive Bayes classifier\n","clf = MultinomialNB()\n","clf.fit(X_train, y_train)\n","\n","# Predict the NER labels for the test set\n","y_pred = clf.predict(X_test)\n","\n","# Print classification report\n","print(classification_report(y_test, y_pred))\n","\n"]},{"cell_type":"code","source":["from sklearn.metrics import classification_report, precision_recall_fscore_support\n","import pandas as pd\n","\n","# Helper function to get true positives, false positives, and false negatives\n","def get_detailed_results(tokens, gold_labels, pred_labels):\n","    results = []\n","\n","    for token, true_label, predicted_label in zip(tokens, gold_labels, pred_labels):\n","        if true_label == predicted_label:\n","            if true_label != 'O':  # O is typically used for non-entity tokens\n","                results.append((token, true_label, predicted_label, 'True Positive'))\n","            else:\n","                results.append((token, true_label, predicted_label, 'True Negative'))\n","        else:\n","            if predicted_label != 'O' and true_label != 'O':  # Both true and predicted are entities\n","                results.append((token, true_label, predicted_label, 'False Positive'))\n","            elif predicted_label == 'O' and true_label != 'O':  # Missed entity (should be tagged but wasn't)\n","                results.append((token, true_label, predicted_label, 'False Negative'))\n","            elif predicted_label != 'O' and true_label == 'O':  # Incorrectly tagged as an entity\n","                results.append((token, true_label, predicted_label, 'False Positive'))\n","            else:\n","                results.append((token, true_label, predicted_label, 'True Negative'))\n","\n","    return results\n","\n","# Prepare tokens from test set for analysis\n","test_tokens = [token for sample in test_data for token in sample['tokens']]\n","\n","# Convert the predicted and true labels into human-readable format\n","y_test_readable = [convert_tags_to_labels(sample['ner_tags']) for sample in test_data]\n","y_test_flat = [label for sublist in y_test_readable for label in sublist]\n","y_pred_flat = list(y_pred)\n","\n","# Ensure both lists (y_test_flat and y_pred_flat) are of equal length\n","assert len(y_test_flat) == len(y_pred_flat)\n","\n","# Get detailed results\n","detailed_results = get_detailed_results(test_tokens, y_test_flat, y_pred_flat)\n","\n","# Convert to DataFrame for easier viewing\n","df_results = pd.DataFrame(detailed_results, columns=['Token', 'Gold Label', 'Predicted Label', 'Result'])\n","print(df_results)\n","\n","# Display a summary of true positives, false positives, and false negatives\n","print(\"Summary:\")\n","print(df_results['Result'].value_counts())\n","\n","# Optionally, you can save the detailed result to a CSV file\n","# df_results.to_csv('ner_detailed_results.csv', index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QsmUxX3C0jai","executionInfo":{"status":"ok","timestamp":1729577971984,"user_tz":-330,"elapsed":587,"user":{"displayName":"Remya Gunasekharan","userId":"01582042654376419065"}},"outputId":"7ff2fa3e-0b6e-4a3e-a42e-8f86b790f693"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["          Token Gold Label Predicted Label          Result\n","0      Hartford      B-ORG           B-ORG   True Positive\n","1             4          O               O   True Negative\n","2        BOSTON      B-ORG           B-ORG   True Positive\n","3             2          O               O   True Negative\n","4            S.      B-PER           B-LOC  False Positive\n","...         ...        ...             ...             ...\n","23047         (          O               O   True Negative\n","23048     NYMEX      B-ORG           B-ORG   True Positive\n","23049   premium          O               O   True Negative\n","23050         )          O               O   True Negative\n","23051         .          O               O   True Negative\n","\n","[23052 rows x 4 columns]\n","Summary:\n","Result\n","True Negative     18344\n","True Positive      2725\n","False Positive     1865\n","False Negative      118\n","Name: count, dtype: int64\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}