{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPGRV2wsyeQUkxgIBX2vmQs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ci3JQWUJyOKg","executionInfo":{"status":"ok","timestamp":1729578003277,"user_tz":-330,"elapsed":3479,"user":{"displayName":"Remya Gunasekharan","userId":"01582042654376419065"}},"outputId":"885152a8-0200-4721-c20b-2ec823f56520"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n","Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.15.2)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"]}],"source":["!pip install datasets"]},{"cell_type":"code","source":["from sklearn.feature_extraction import DictVectorizer\n","from sklearn.metrics import classification_report\n","from sklearn.tree import DecisionTreeClassifier\n","from datasets import load_dataset\n","import nltk\n","\n","# Download necessary NLTK data\n","nltk.download('averaged_perceptron_tagger')\n","\n","# Load the CoNLL 2003 dataset\n","dataset = load_dataset('conll2003')\n","\n","# Reduce the dataset size further (e.g., use only 25% of the training data)\n","train_data = dataset['train'].shuffle(seed=42).select(range(int(len(dataset['train']) * 0.50)))\n","test_data = dataset['test'].shuffle(seed=42).select(range(int(len(dataset['test']) * 0.50)))\n","\n","# Get NER tag mappings from integers to label strings\n","label_names = dataset['train'].features['ner_tags'].feature.names\n","\n","# Convert NER tags into readable labels\n","def convert_tags_to_labels(tag_list):\n","    return [label_names[tag] for tag in tag_list]\n","\n","# Feature extraction function for each word\n","def extract_features(sentence, index):\n","    word = sentence[index]\n","    features = {\n","        'word': word,\n","        'is_first': index == 0,\n","        'is_last': index == len(sentence) - 1,\n","        'is_capitalized': word[0].isupper(),\n","        'is_all_caps': word.isupper(),\n","        'is_all_lower': word.islower(),\n","        'prefix-1': word[0],\n","        'prefix-2': word[:2],\n","        'prefix-3': word[:3],\n","        'suffix-1': word[-1],\n","        'suffix-2': word[-2:],\n","        'suffix-3': word[-3:],\n","        'prev_word': '' if index == 0 else sentence[index - 1],\n","        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n","        'is_numeric': word.isdigit(),\n","        'capitals_inside': word[1:].lower() != word[1:]\n","    }\n","    return features\n","\n","# Prepare dataset for feature extraction\n","def transform_to_dataset(dataset):\n","    X, y = [], []\n","    for i in range(len(dataset)):\n","        tokens = dataset[i]['tokens']\n","        tags = convert_tags_to_labels(dataset[i]['ner_tags'])\n","        for index in range(len(tokens)):\n","            X.append(extract_features(tokens, index))\n","            y.append(tags[index])\n","    return X, y\n","\n","# Transform the train and test datasets\n","X_train, y_train = transform_to_dataset(train_data)\n","X_test, y_test = transform_to_dataset(test_data)\n","\n","# Convert features to numerical vectors with sparse matrix\n","vec = DictVectorizer(sparse=True)\n","X_train = vec.fit_transform(X_train)\n","X_test = vec.transform(X_test)\n","\n","# Initialize and train the Decision Tree classifier\n","clf = DecisionTreeClassifier(random_state=42)\n","clf.fit(X_train, y_train)\n","\n","# Make predictions and evaluate\n","y_pred = clf.predict(X_test)\n","print(classification_report(y_test, y_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"joKHsi5lyPFE","executionInfo":{"status":"ok","timestamp":1729578044724,"user_tz":-330,"elapsed":37192,"user":{"displayName":"Remya Gunasekharan","userId":"01582042654376419065"}},"outputId":"1e3a112a-d7cf-45fd-ba6f-f5b73a23a7d2"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","       B-LOC       0.71      0.69      0.70       809\n","      B-MISC       0.63      0.69      0.66       341\n","       B-ORG       0.60      0.52      0.56       848\n","       B-PER       0.60      0.62      0.61       810\n","       I-LOC       0.56      0.44      0.50       126\n","      I-MISC       0.60      0.64      0.62       102\n","       I-ORG       0.52      0.52      0.52       414\n","       I-PER       0.66      0.72      0.68       581\n","           O       0.98      0.99      0.98     19021\n","\n","    accuracy                           0.92     23052\n","   macro avg       0.65      0.65      0.65     23052\n","weighted avg       0.92      0.92      0.92     23052\n","\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import classification_report, precision_recall_fscore_support\n","import pandas as pd\n","\n","# Helper function to get true positives, false positives, and false negatives\n","def get_detailed_results(tokens, gold_labels, pred_labels):\n","    results = []\n","\n","    for token, true_label, predicted_label in zip(tokens, gold_labels, pred_labels):\n","        if true_label == predicted_label:\n","            if true_label != 'O':  # O is typically used for non-entity tokens\n","                results.append((token, true_label, predicted_label, 'True Positive'))\n","            else:\n","                results.append((token, true_label, predicted_label, 'True Negative'))\n","        else:\n","            if predicted_label != 'O' and true_label != 'O':  # Both true and predicted are entities\n","                results.append((token, true_label, predicted_label, 'False Positive'))\n","            elif predicted_label == 'O' and true_label != 'O':  # Missed entity (should be tagged but wasn't)\n","                results.append((token, true_label, predicted_label, 'False Negative'))\n","            elif predicted_label != 'O' and true_label == 'O':  # Incorrectly tagged as an entity\n","                results.append((token, true_label, predicted_label, 'False Positive'))\n","            else:\n","                results.append((token, true_label, predicted_label, 'True Negative'))\n","\n","    return results\n","\n","# Prepare tokens from test set for analysis\n","test_tokens = [token for sample in test_data for token in sample['tokens']]\n","\n","# Convert the predicted and true labels into human-readable format\n","y_test_readable = [convert_tags_to_labels(sample['ner_tags']) for sample in test_data]\n","y_test_flat = [label for sublist in y_test_readable for label in sublist]\n","y_pred_flat = list(y_pred)\n","\n","# Ensure both lists (y_test_flat and y_pred_flat) are of equal length\n","assert len(y_test_flat) == len(y_pred_flat)\n","\n","# Get detailed results\n","detailed_results = get_detailed_results(test_tokens, y_test_flat, y_pred_flat)\n","\n","# Convert to DataFrame for easier viewing\n","df_results = pd.DataFrame(detailed_results, columns=['Token', 'Gold Label', 'Predicted Label', 'Result'])\n","print(df_results)\n","\n","# Display a summary of true positives, false positives, and false negatives\n","print(\"Summary:\")\n","print(df_results['Result'].value_counts())\n","\n","# Optionally, you can save the detailed result to a CSV file\n","# df_results.to_csv('ner_detailed_results.csv', index=False)\n"],"metadata":{"id":"x9Ao212a42Io","executionInfo":{"status":"ok","timestamp":1729578104803,"user_tz":-330,"elapsed":1571,"user":{"displayName":"Remya Gunasekharan","userId":"01582042654376419065"}},"outputId":"7194ad7b-e0ae-4c5b-9303-5a5841452797","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["          Token Gold Label Predicted Label          Result\n","0      Hartford      B-ORG           B-ORG   True Positive\n","1             4          O               O   True Negative\n","2        BOSTON      B-ORG           B-ORG   True Positive\n","3             2          O               O   True Negative\n","4            S.      B-PER           B-PER   True Positive\n","...         ...        ...             ...             ...\n","23047         (          O               O   True Negative\n","23048     NYMEX      B-ORG               O  False Negative\n","23049   premium          O               O   True Negative\n","23050         )          O               O   True Negative\n","23051         .          O               O   True Negative\n","\n","[23052 rows x 4 columns]\n","Summary:\n","Result\n","True Negative     18744\n","True Positive      2491\n","False Positive     1503\n","False Negative      314\n","Name: count, dtype: int64\n"]}]}]}